---
title: "seesaw"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{seesaw}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(seesaw)
library(ggplot2)
library(sf)
library(GpGp)
```

### Load the Data

```{r}
# Get file paths
full_table_path <- system.file("Data", "full_table.RData", package = "seesaw")
station_info_path <- system.file("Data", "station_info.RData", package = 
                                   "seesaw")
shp_file_path <- system.file("Data", "shp_file.Rdata", package = "seesaw")

# Load the data file
load(full_table_path)
load(station_info_path)
load(shp_file_path)
```


1. Make a map of the average temperature at each station for the month of March 
2024.

```{r}
# Get list of station ids 
station_ids <- station_info$station_id

# Filter data to include only March 2024, find average March 2024 temperature for each station
march_data <- full_table[full_table$LST_DATE >= "2024-03-01" 
                         & full_table$LST_DATE <= "2024-03-31", ]
average_temps <- aggregate(march_data$T_DAILY_AVG,
                           by = list( march_data$WBANNO ),
                           FUN = mean )

# Create a new data frame with station ids, average temperatures,lat and lon
df <- data.frame(station_id = unique(march_data$WBANNO), 
                 average_temp = average_temps$x)
# Merge df with station_info to get lat and lon
df <- merge(df, station_info, by.x = "station_id", by.y = "station_id")

# Drop NAs
df <- df[complete.cases(df), ]

# Plot the USA shapefile and add the average temperature data as points
usa_boundary <- st_crop(st_make_valid(shp_file), xmin = -125, xmax = -66.93457, 
                    ymin = 22.396308, ymax = 49.384358)

df_sf <- st_as_sf(df, coords = c("longitude", "latitude"), crs = 
                    st_crs(usa_boundary))
coordinates <- st_coordinates(df_sf)
df_sf$x <- coordinates[,1]
df_sf$y <- coordinates[,2]

ggplot() +
  geom_sf(data = usa_boundary) +
  coord_sf(lims_method = "geometry_bbox") +
  geom_point(data = df_sf, aes(color = average_temp, x = x, y = y), size = 1) +
  theme_minimal() +
  labs(title = "Average Temperature at Each Station for March 2024", x = "Longitude", y = "Latitude") +
  theme(plot.title = element_text(hjust = 0.5))
  

```

2. Fit a spatial model and plot an interpolated map of average temperatures for March 2024. Consider
including elevation in your model.

```{r}

res <- 100
spatial_model <- interpolate_grid("2024-03-01", "2024-03-31", "T_DAILY_AVG", res)
grid <- usagrid(res)
graph_interp(spatial_model, grid) + labs(x = "Longitude", y = "Latitude", fill = "Interpolated Average Temperature")


```

3. Estimate the warmest and coldest day of the year for each station, and plot those days on two maps. Think carefully about how to represent the days numerically. 

In your report, describe the statistical analysis that you used for estimating the warmest and coldest days at each station, including writing down any statistical models in mathematical notation. Be sure to define all your symbols and assumptions. 

Interpolate maps of the warmest and coldest days, and plot the interpolated maps of warmest and coldest days. 

```{r}

warmest_coldest <- function(station_id){
  cycle <- yearly_cycle_station(station_id, "T_DAILY_AVG")
  warmest_day <- cycle$DOY[which.max(cycle$Expected_T_DAILY_AVG)]
  coldest_day <- cycle$DOY[which.min(cycle$Expected_T_DAILY_AVG)]
  c(warmest_day, coldest_day)
}

# Preallocate the data frame
warmest_coldest_days <- data.frame(station_id = station_ids, warmest_day = numeric(length(station_ids)), coldest_day = numeric(length(station_ids)))

# Loop through each station
for (i in 1:length(station_ids)){
  # Assign values directly without using c()
  warmest_coldest_days[i, c("warmest_day", "coldest_day")] <- warmest_coldest(station_ids[i])
}

# Plot the shapefile and add the warmest day data as points
df_warmest <- merge(warmest_coldest_days, station_info, by.x = "station_id", by.y = "station_id")

# Drop NA
#df_warmest <- df_warmest[complete.cases(df_warmest),]

df_warmest_sf <- st_as_sf(df_warmest, coords = c("longitude", "latitude"), crs = 
                           st_crs(usa_boundary))

coordinates <- st_coordinates(df_warmest_sf)
df_warmest_sf$x <- coordinates[,1]
df_warmest_sf$y <- coordinates[,2]

ggplot() +
  geom_sf(data = usa_boundary) +
  coord_sf(lims_method = "geometry_bbox") +
  geom_point(data = df_warmest_sf, aes(color = warmest_day, x = x, y = y), size = 1) +
  theme_minimal() +
  labs(title = "Warmest Day of the Year for Each Station") +
  theme(plot.title = element_text(hjust = 0.5))

# Plot the shapefile and add the coldest day data as points
ggplot() +
  geom_sf(data = usa_boundary) +
  coord_sf(lims_method = "geometry_bbox") +
  geom_point(data = df_warmest_sf, aes(color = coldest_day, x = x, y = y), size = 1) +
  theme_minimal() +
  labs(title = "Coldest Day of the Year for Each Station") +
  theme(plot.title = element_text(hjust = 0.5))

                                   


```

Statistical Model:

The estimated average warmest and coldest day of the year was calculated by fitting a sinusoidal model to the daily average temperature data for each station. The model is given by:

$Y_i = \beta_0 + \beta_1 * \sin(2\pi d/365) + \beta_2*\cos(2\pi d/365) + \epsilon_i$

where $Y_i$ is the daily average temperature, $d$ is the day of the year, and $\epsilon_i$ is the error term. The estimated warmest day of the year is the day with the highest expected temperature, and the estimated coldest day of the year is the day with the lowest expected temperature.

Assumptions:
1. The daily average temperature data is sinusoidal with a period of 365 days.
2. The daily average temperature data is stationary over time.
3. The error term is normally distributed with mean 0 and constant variance.

```{r}
# Interpolate maps of the warmest and coldest days

# BUGGED ASK AVA FOR HELP

y_warm <- df_warmest$warmest_day
y_cold <- df_warmest$coldest_day
locs <- df_warmest[, c("longitude", "latitude")]
locs$longitude <- as.numeric(locs$longitude)
locs$latitude <- as.numeric(locs$latitude)
X <- cbind(1, locs)
grid <- usagrid(100)
warm_model <- fit_model(y_warm,locs, X, covfun_name = "matern_sphere", 
                        silent = T)
cold_model <- fit_model(y_cold,locs, X, covfun_name = "matern_sphere",
                            silent = T)

Xpred <- cbind(1, grid[, c("x", "y")])
pred_locs <- grid[, c("x", "y")]

warm_pred <- predictions(warm_model,pred_locs, Xpred)
cold_pred <- predictions(cold_model,pred_locs, Xpred)

graph_interp(warm_pred, grid)
graph_interp(cold_pred, grid)
```


4. Make a single plot of the estimated yearly cycles for 10 different stations, highlighting a diversity of climates around the contiguous USA. Your plot should clearly indicate which cycle is from which station. 

```{r}

# Select 10 stations from around the contiguous USA
# ( Maine, Washington, Arizona, Wyoming, Oklahoma, Texas, Kentucky, Florida, 
#   Michigan, Pennsylvania )
stations <- c("94645", "04223", "53169", "04131", "53182", "12987", "63849", 
              "92826", "54810", "03761")
# Select 10 colors
cols <- c("chartreuse1", "darkcyan", "dodgerblue4", "goldenrod1", "darkorange1",
          "deeppink3", "green4", "mediumpurple", "midnightblue", "firebrick3")
# Initialize plot
plt <- ggplot() + 
  labs(title = "Estimated Yearly Cycles", 
       x = "DOY", y = "Expected_T_DAILY_AVG")
# Calculate and plot estimated yearly cycle for each station
for (i in 1:10){
  cycle <- yearly_cycle_station(stations[i])
  cycle$station <- stations[i]
  plt <- plt + geom_line(data = cycle, 
                           aes(x = DOY, y = Expected_T_DAILY_AVG,
                               color = station))
}
# Add legend
plt <- plt + scale_color_manual(name = "Station ID", breaks = stations, 
                                values = setNames(cols, stations))
plt
```

5. Estimate the trend over the years for each station, in units of degrees Fahrenheit per year, and plot the trend values on a map. Indicate visually on your map which of the trends are statistically significant.

In your report, write the statistical model that you used in mathematical notation. Be sure to define all your symbols and assumptions.

Interpolate the estimated trends to a grid, and plot them on a map. For the interpolations, you may consider using only the trend estimates whose standard errors are sufficiently small. 

```{r}
# Find the temperature trends for each station (since 2000)
temp_trends <- trend_of_temps()

# Create a new data frame with station ids, temperature trend, lat and long
station_trends <- data.frame(station_id = temp_trends$station_id, 
                             trend = temp_trends$trend_Overall)
# Merge df with station_info to get lat and lon
station_trends <- merge(station_trends, station_info, by.x = "station_id", 
                        by.y = "station_id")

# Determine which trends are statistically significant
station_trends$signif

# Drop NAs
station_trends <- station_trends[complete.cases(station_trends), ]

# Plot the USA shapefile
usa_boundary <- st_crop(st_make_valid(shp_file), xmin = -125, xmax = -66.93457, 
                    ymin = 22.396308, ymax = 49.384358)

station_trends_sf <- st_as_sf(station_trends, 
                              coords = c("longitude", "latitude"), 
                              crs = st_crs(usa_boundary))
coordinates <- st_coordinates(station_trends_sf)
station_trends_sf$x <- coordinates[,1]
station_trends_sf$y <- coordinates[,2]

# Plot overall trends
ggplot() +
  geom_sf(data = usa_boundary) +
  coord_sf(lims_method = "geometry_bbox") +
  geom_point(data = station_trends_sf, 
             aes(color = trend, x = x, y = y, shape = signif), 
             size = 1) + theme_minimal() +
  labs(title = "Temperature Trends Since 2000", 
       x = "Longitude", y = "Latitude") +
  theme(plot.title = element_text(hjust = 0.5))
  

```
```{r}
# Interpolate trends for contigous US
```

6. Find a reputable source for the average temperature trend in the contiguous USA over the past 20 years, and compare your results to the source's.


