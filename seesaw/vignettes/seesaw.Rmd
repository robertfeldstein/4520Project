---
title: "seesaw"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{seesaw}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(seesaw)
library(ggplot2)
library(sf)
library(GpGp)
```

### Load the Data

```{r}
# Get file paths
full_table_path <- system.file("Data", "full_table.RData", package = "seesaw")
station_info_path <- system.file("Data", "station_info.RData", package = 
                                   "seesaw")
shp_file_path <- system.file("Data", "shp_file.Rdata", package = "seesaw")

# Load the data file
load(full_table_path)
load(station_info_path)
load(shp_file_path)
```


1. Make a map of the average temperature at each station for the month of March 
2024.

```{r}
# Get list of station ids 
station_ids <- station_info$station_id

# Use time_series_station to filter the data to March 2024 for each station
# Initialize empty vector to hold average temperatures
average_temps <- numeric(length(station_ids))

# # Loop through each station
# for (i in 1:length(station_ids)){
#   time_series <- time_series_station(station_ids[i], "2024-03-01", "2024-03-31")
#   average_temps[i] <- mean(time_series$T_DAILY_AVG, na.rm = TRUE)
# }

march_data <- full_table[full_table$LST_DATE >= "2024-03-01" & full_table$LST_DATE <= "2024-03-31",]
average_temps <- aggregate(march_data$T_DAILY_AVG,by=list(march_data$WBANNO),FUN=mean)

# Create a new data frame with station ids, average temperatures,lat and lon

df <- data.frame(station_id = unique(march_data$WBANNO), av_temp = average_temps$x)
# Merge df with station_info to get lat and lon
df <- merge(df, station_info, by.x = "station_id", by.y = "station_id")

#Drop na
df <- df[complete.cases(df),]

# Plot the shapefile and add the average temperature data as points
usa_boundary <- st_crop(st_make_valid(shp_file), xmin = -125, xmax = -66.93457, 
                    ymin = 22.396308, ymax = 49.384358)

df_sf <- st_as_sf(df, coords = c("longitude", "latitude"), crs = 
                    st_crs(usa_boundary))
coordinates <- st_coordinates(df_sf)
df_sf$x <- coordinates[,1]
df_sf$y <- coordinates[,2]

# Plot the shapefile and add the average temperature data as points
ggplot() +
  geom_sf(data = usa_boundary) +
  coord_sf(lims_method = "geometry_bbox") +
  geom_point(data = df_sf, aes(color = av_temp, x = x, y = y), size = 1) +
  theme_minimal() +
  labs(title = "Average Temperature at Each Station for March 2024") +
  theme(plot.title = element_text(hjust = 0.5))
  

```

2. Fit a spatial model and plot an interpolated map of average temperatures for March 2024. Consider
including elevation in your model.

```{r}

res <- 100
spatial_model <- interpolate_grid("2024-03-01", "2024-03-31", "T_DAILY_AVG", res)
grid <- usagrid(res)
graph_interp(spatial_model, grid)


```

3. Estimate the warmest and coldest day of the year for each station, and plot those days on two maps. Think carefully about how to represent the days numerically. 

In your report, describe the statistical analysis that you used for estimating the warmest and coldest days at each station, including writing down any statistical models in mathematical notation. Be sure to define all your symbols and assumptions. 

Interpolate maps of the warmest and coldest days, and plot the interpolated maps of warmest and coldest days. 

```{r}

warmest_coldest <- function(station_id){
  cycle <- yearly_cycle_station(station_id, "T_DAILY_AVG")
  warmest_day <- cycle$DOY[which.max(cycle$Expected_T_DAILY_AVG)]
  coldest_day <- cycle$DOY[which.min(cycle$Expected_T_DAILY_AVG)]
  c(warmest_day, coldest_day)
}

# Preallocate the data frame
warmest_coldest_days <- data.frame(station_id = station_ids, warmest_day = numeric(length(station_ids)), coldest_day = numeric(length(station_ids)))

# Loop through each station
for (i in 1:length(station_ids)){
  # Assign values directly without using c()
  warmest_coldest_days[i, c("warmest_day", "coldest_day")] <- warmest_coldest(station_ids[i])
}

# Plot the shapefile and add the warmest day data as points
df_warmest <- merge(warmest_coldest_days, station_info, by.x = "station_id", by.y = "station_id")

# Drop na
#df_warmest <- df_warmest[complete.cases(df_warmest),]

df_warmest_sf <- st_as_sf(df_warmest, coords = c("longitude", "latitude"), crs = 
                           st_crs(usa_boundary))

coordinates <- st_coordinates(df_warmest_sf)
df_warmest_sf$x <- coordinates[,1]
df_warmest_sf$y <- coordinates[,2]

ggplot() +
  geom_sf(data = usa_boundary) +
  coord_sf(lims_method = "geometry_bbox") +
  geom_point(data = df_warmest_sf, aes(color = warmest_day, x = x, y = y), size = 1) +
  theme_minimal() +
  labs(title = "Warmest Day of the Year for Each Station") +
  theme(plot.title = element_text(hjust = 0.5))

# Plot the shapefile and add the coldest day data as points
ggplot() +
  geom_sf(data = usa_boundary) +
  coord_sf(lims_method = "geometry_bbox") +
  geom_point(data = df_warmest_sf, aes(color = coldest_day, x = x, y = y), size = 1) +
  theme_minimal() +
  labs(title = "Coldest Day of the Year for Each Station") +
  theme(plot.title = element_text(hjust = 0.5))

                                   


```

Statistical Model:

The estimated average warmest and coldest day of the year was calculated by fitting a sinusoidal model to the daily average temperature data for each station. The model is given by:

$Y_i = \beta_0 + \beta_1 * \sin(2\pi d/365) + \beta_2*\cos(2\pi d/365) + \epsilon_i$

where $Y_i$ is the daily average temperature, $d$ is the day of the year, and $\epsilon_i$ is the error term. The estimated warmest day of the year is the day with the highest expected temperature, and the estimated coldest day of the year is the day with the lowest expected temperature.

Assumptions:
1. The daily average temperature data is sinusoidal with a period of 365 days.
2. The daily average temperature data is stationary over time.
3. The error term is normally distributed with mean 0 and constant variance.

```{r}
# Interpolate maps of the warmest and coldest days

# BUGGED ASK AVA FOR HELP

# y_warm <- df_warmest$warmest_day
# y_cold <- df_warmest$coldest_day
# locs <- df_warmest[, c("longitude", "latitude")]
# grid <- usagrid(100)
# debug(fit_model)
# warm_model <- fit_model(y_warm,locs, covfun_name = "matern_sphere",
#                            silent = T)
# cold_model <- fit_model(y_cold,locs, covfun_name = "matern_sphere",
#                            silent = T)
# 
# Xpred <- model.matrix( ~ 1, data = grid)
# pred_locs <- grid[, c("x", "y")]
# 
# warm_pred <- predictions(warm_model,pred_locs, Xpred)
# cold_pred <- predictions(cold_model,pred_locs, Xpred)

```


4. Make a single plot of the estimated yearly cycles for 10 different stations, highlighting a diversity of climates around the contiguous USA. Your plot should clearly indicate which cycle is from which station. 

```{r}

```

5. Estimate the trend over the years for each station, in units of degrees Fahrenheit per year, and plot the trend values on a map. Indicate visually on your map which of the trends are statistically significant.

In your report, write the statistical model that you used in mathematical notation. Be sure to define all your symbols and assumptions.

Interpolate the estimated trends to a grid, and plot them on a map. For the interpolations, you may consider using only the trend estimates whose standard errors are sufficiently small. 

```{r}

```

6. Find a reputable source for the average temperature trend in the contiguous USA over the past 20 years, and compare your results to the source's.


